<div>
    <h1 style="text-align: center;">How to Improve API Performance</h1>
    <hr>
    <img src="../../../images/api_performance.PNG" alt="Spring" style="display: block; margin: auto; width: 50%" class="img-fluid">
    <br>
    
        <h5>Pagination</h3>
        <ul>
          <li>Limits the amount of data returned in a single API response, reducing server load and response time.</li>
          <li>Improves user experience by fetching only the required subset of data instead of loading everything at once.</li>
          <li>Common pagination strategies: offset/limit(Traditional Pagination), cursor-based pagination (more efficient for large datasets).</li>
          <ul>
            <li><b>offset/limit: </b>Inefficient for large datasets because the server has to scan through previous records to get the required set 
                (e.g., scanning through 1 million records to get the 10,000th to 10,100th records).</li>
            <li><b>cursor-based pagination: </b>If fetching a list of users sorted by ID, the cursor can be the last user ID on the current page. For the next page, 
                the API fetches users with an ID greater than the cursor value.</li>
          </ul>
          <li><em>Tricky point:</em> Handling edge cases like missing pages, or items changing during pagination (ensure consistency).</li>
        </ul>
      
        <h5>Async Logging</h3>
        <ul>
          <li>Moves logging operations to asynchronous processes to avoid blocking the main API execution thread.</li>
          <li>Improves performance by offloading tasks such as writing logs to disk or a logging service.</li>
          <li>Can use a message queue (e.g., Kafka, RabbitMQ) to store logs asynchronously.</li>
          <li>By using multithreading, batch processing, and a retry mechanism, you can significantly improve the performance of API calls and record processing. 
            The key is to:</li>
          <ul>
            <li>Fetch and process records concurrently.</li>
            <li>Handle paginated responses efficiently with a cursor-based approach.</li>
            <li>Implement retry logic to ensure resilience in case of network failures.</li>
          </ul>
          <li>This approach minimizes bottlenecks and optimizes system resource usage, improving the overall performance of your API-consuming application.</li>
          <li><em>Tricky point:</em> Ensuring log consistency when using asynchronous logging (potential log loss during crashes).</li>
        </ul>
     
        <h5>Caching</h3>
        <ul>
          <li>Caches frequently accessed data to reduce database queries and repetitive processing.</li>
          <li>In-memory caches (e.g., Redis, Memcached) can drastically improve performance for read-heavy APIs.</li>
          <li>How Caching Improves API Performance:</li>
          <ul>
            <li>Reduces Latency and Response Time</li>
            <li>Reduces Database Load</li>
            <li>For APIs that pull data from external services or APIs, caching reduces the number of outgoing network requests, lowering bandwidth usage and potentially reducing costs if using third-party APIs.</li>
            <li>Improves Scalability: Caching allows the server to handle more requests by offloading repetitive tasks and using fewer resources for each request.</li>
            <li>Enables High Availability and Reliability</li>
            <li>Reduces Computational Overhead</li>
          </ul>
          <li>Consider caching strategies: time-based expiration (TTL), cache invalidation upon data updates.</li>
          <li><em>Tricky point:</em> Cache invalidation is hard â€” improper cache expiry can cause stale data issues or cache thrashing.</li>
        </ul>
      
        <h5>Payload Compression</h3>
        <ul>
          <li>Compresses the response payload (e.g., using Gzip or Brotli) to reduce data transfer size, improving network performance.</li>
          <li>Particularly useful for APIs with large responses, like JSON or XML data.</li>
          <li>Ensure that clients are capable of decompressing the payload.</li>
          <li><em>Tricky point:</em> Balance between compression level and CPU overhead. Excessive compression can slow down server processing.</li>
        </ul>
      
      
        <h5>Connection Pooling</h3>
        <ul>
          <li>Reuses established network connections instead of creating new connections for every request, saving time and resources.</li>
          <li>Reduces the overhead of creating and tearing down connections (especially for database connections).</li>
          <li>Connection pools maintain a pool of active, reusable connections (e.g., for databases or external APIs).</li>
          <li><em>Tricky point:</em> Properly sizing the connection pool to prevent resource exhaustion or underutilization.</li>
        </ul>
      
    </ul>
  </div>
  
  <div>
    <h5>Tricky Points about API Performance (Potential Interview Questions)</h3>
    <ul>
      <li><strong>How do you handle rate limiting?</strong> Design a strategy for protecting the API from abuse or heavy traffic while ensuring fair usage (e.g., token bucket, leaky bucket).</li>
      <li><strong>How do you handle large payloads?</strong> Consider splitting payloads, using streaming APIs (e.g., chunked encoding), and ensuring client-side handling of partial data.</li>
      <li><strong>How to avoid database bottlenecks?</strong> Discuss read/write optimization techniques, indexing, query optimization, and database replication or sharding.</li>
      <li><strong>How do you handle timeouts and retries?</strong> Implement client-side retries with exponential backoff to handle transient failures. Proper timeout configurations are essential to avoid resource hanging.</li>
      <li><strong>How do you ensure API scalability?</strong> Talk about horizontal scaling (load balancers, stateless APIs), vertical scaling, and distributed architectures (microservices).</li>
    </ul>
  </div>
  
  <div>
    <h5>Other Tips for API Performance</h3>
    <ul>
      <li><strong>Optimize database queries:</strong> Ensure queries are optimized, with proper indexes and no redundant joins or subqueries.</li>
      <li><strong>Monitor API metrics:</strong> Use tools like Prometheus, Grafana, or New Relic to monitor performance metrics (latency, throughput, error rates) and adjust accordingly.</li>
      <li><strong>Implement rate limiting:</strong> Use rate limiting and throttling techniques to avoid overloading your API under high-traffic conditions.</li>
      <li><strong>Versioning:</strong> Implement API versioning to ensure backward compatibility when making changes to the API, avoiding breaking changes for clients.</li>
      <li><strong>Use CDN for static resources:</strong> Offload delivery of static content (e.g., images, CSS, JS files) to a CDN for faster access and reduced server load.</li>
    </ul>
  </div>
  