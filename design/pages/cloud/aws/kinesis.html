<div class="custom-container">
<h3 class="toc-title">Table of Contents</h3>
<ol class="toc-list">
<li><a href="#kinesis-overview">Amazon Kinesis Overview</a></li>
<li><a href="#kinesis-video-streams">Kinesis Video Streams</a></li>
<li><a href="#kinesis-data-streams">Kinesis Data Streams</a>
<ol>
<li><a href="#kds-basics">Basics & Use Cases</a></li>
<li><a href="#kds-producers">Producers</a></li>
<li><a href="#kds-records">Records</a></li>
<li><a href="#kds-shards">Shards</a></li>
<li><a href="#kds-resharding">Resharding (Split/Merge)</a></li>
<li><a href="#kds-consumers">Consumers</a></li>
<li><a href="#kds-security">Security & Durability</a></li>
</ol>
</li>
<li><a href="#kinesis-data-firehose">Kinesis Data Firehose</a>
<ol>
<li><a href="#kdf-basics">Basics & Features</a></li>
<li><a href="#kdf-components">Components (Source, Stream, Record, Destination)</a></li>
<li><a href="#kdf-destinations">Destinations</a></li>
<li><a href="#kdf-transformation">Data Transformation</a></li>
<li><a href="#kdf-security">Security</a></li>
</ol>
</li>
<li><a href="#kinesis-data-analytics">Kinesis Data Analytics</a>
<ol>
<li><a href="#kda-basics">Basics & Use Cases</a></li>
<li><a href="#kda-components">Application Components</a></li>
<li><a href="#kda-inputs">Input & Output</a></li>
</ol>
</li>
<li><a href="#kinesis-client-library">Kinesis Client Library (KCL)</a></li>
<li><a href="#kinesis-security">Kinesis Security (General)</a></li>
<li><a href="#sqs-sns-kinesis-compare">SQS vs SNS vs Kinesis Comparison</a></li>
<li><a href="#kinesis-exam-tips">Important Exam Tips & Tricks</a></li>
</ol>
</div>
<hr>

<h3 id="kinesis-overview">Amazon Kinesis Overview</h3>
<ul>
<li><strong>Purpose:</strong> Collect, process, and analyze real-time, streaming data for timely insights.</li>
<li>A collection of services for processing streams of various data types.</li>
<li>Data processed in "shards," each ingesting 1000 records/second.</li>
<li>Default limit of 500 shards (can be increased).</li>
<li>A record consists of a partition key, sequence number, and data blob (up to 1 MB).</li>
<li><strong>Transient Data Store:</strong> Default retention of 24 hours, configurable up to 7 days.</li>
<li>Four main services: Video Streams, Data Streams, Data Firehose, Data Analytics.</li>
</ul>
<hr>

<h3 id="kinesis-video-streams">Kinesis Video Streams</h3>
<ul>
<li><strong>Purpose:</strong> Securely stream video from connected devices to AWS for analytics, ML, and other processing.</li>
<li>Durably stores, encrypts, and indexes video data streams.</li>
<li>Producers provide data streams; Consumers receive and process.</li>
<li>Stores data for 24 hours (default), up to 7 days.</li>
<li>Supports encryption at rest with server-side encryption (KMS).</li>
<li>Exam Relevance: Does not appear much on AWS exams.</li>
</ul>
<hr>

<h3 id="kinesis-data-streams">Kinesis Data Streams</h3>
<h4 id="kds-basics">Basics & Use Cases</h4>
<ul>
<li><strong>Purpose:</strong> Build custom applications to process or analyze streaming data for specialized needs.</li>
<li>Enables real-time processing of streaming big data.</li>
<li>Useful for rapidly moving data off data producers and continuously processing it.</li>
<li><strong>Key Difference:</strong> Stores data for later processing by applications (unlike Firehose, which delivers directly).</li>
<li><strong>Common Use Cases:</strong> Accelerated log/data feed intake, real-time metrics/reporting, real-time data analytics, complex stream processing.</li>
</ul>

<h4 id="kds-producers">Producers</h4>
<ul>
<li>Continually push data to Kinesis Data Streams.</li>
<li>Methods: Kinesis Streams API, Kinesis Producer Library (KPL), Kinesis Agent.</li>
</ul>

<h4 id="kds-records">Records</h4>
<ul>
<li>Unit of data stored in a Kinesis Data Stream.</li>
<li>Composed of: sequence number, partition key, and data blob.</li>
<li><strong>Data Blob:</strong> The actual data payload (max 1 MB before Base64-encoding).</li>
<li><strong>Retention:</strong> Default 24 hours, can be extended to 7 days.</li>
</ul>

<h4 id="kds-shards">Shards</h4>
<ul>
<li>Base throughput unit of a Kinesis Data Stream.</li>
<li><strong>Capacity per Shard:</strong> 1 MB/sec data input, 2 MB/sec data output.</li>
<li>Supports up to 1000 PUT records/second.</li>
<li>A stream is composed of one or more shards; total capacity is sum of shard capacities.</li>
</ul>

<h4 id="kds-resharding">Resharding (Split/Merge)</h4>
<ul>
<li>Adjusts the number of shards to adapt to changes in data flow rate.</li>
<li><strong>Shard Split:</strong> Divides a single shard into two. Increases shard count, data capacity, and cost.</li>
<li><strong>Shard Merge:</strong> Combines two shards into one. Reduces shard count, data capacity, and cost.</li>
</ul>

<h4 id="kds-consumers">Consumers</h4>
<ul>
<li>EC2 instances (or other compute) that analyze data received from a stream.</li>
<li>Known as Amazon Kinesis Streams Applications.</li>
<li>Scale consumers by adding/removing shards when data rate increases/decreases.</li>
<li>Partition Keys: Used to group data by shard within a stream. Ensures all records with the same partition key go to the same shard. (<strong>Exam Tip!</strong>)</li>
</ul>

<h4 id="kds-security">Security & Durability</h4>
<ul>
<li>Replicates synchronously across three AZs for high durability.</li>
<li>Supports encryption at rest using KMS master keys. Producers/consumers need KMS key access.</li>
</ul>
<hr>

<h3 id="kinesis-data-firehose">Kinesis Data Firehose</h3>
<h4 id="kdf-basics">Basics & Features</h4>
<ul>
<li><strong>Definition:</strong> Easiest way to load streaming data into data stores and analytics tools.</li>
<li>Captures, transforms, and loads streaming data.</li>
<li>Enables near real-time analytics with existing BI tools.</li>
<li>Can use Kinesis Data Streams as a source.</li>
<li>Key Difference: Delivers data directly to AWS services (no need to write an application or manage resources).</li>
<li>Can batch, compress, and encrypt data before loading.</li>
<li>Synchronously replicates data across three AZs during transport.</li>
<li>Stores data records for up to 24 hours.</li>
<li>No shards: Totally automated and managed service. (<strong>Exam Tip!</strong>)</li>
</ul>

<h4 id="kdf-components">Components (Source, Stream, Record, Destination)</h4>
<ul>
<li><strong>Source:</strong> Where streaming data is generated/captured.</li>
<li><strong>Delivery Stream:</strong> Underlying entity of Firehose.</li>
<li><strong>Record:</strong> Data sent to a delivery stream (max 1000 KB before Base64-encoding).</li>
<li><strong>Destination:</strong> Data store where data is delivered.</li>
</ul>

<h4 id="kdf-destinations">Destinations</h4>
<ul>
<li>Amazon S3 (common for raw data backup).</li>
<li>Amazon Redshift (data loaded via S3 <code>COPY</code> command).</li>
<li>Amazon Elasticsearch Service.</li>
<li>Splunk.</li>
</ul>

<h4 id="kdf-transformation">Data Transformation</h4>
<ul>
<li>Can invoke an AWS Lambda function to transform incoming data before delivery.</li>
<li>Optional backup of source data to another S3 bucket if transformation is enabled.</li>
</ul>

<h4 id="kdf-security">Security</h4>
<ul>
<li>Can encrypt data with an existing KMS key.</li>
<li>Server-side encryption can be used if Kinesis Data Streams is the source.</li>
</ul>
<hr>

<h3 id="kinesis-data-analytics">Kinesis Data Analytics</h3>
<h4 id="kda-basics">Basics & Use Cases</h4>
<ul>
<li><strong>Definition:</strong> Easiest way to process and analyze real-time, streaming data.</li>
<li>Can use standard SQL queries to process Kinesis data streams.</li>
<li>Provides real-time analysis.</li>
<li><strong>Use Cases:</strong> Generate time-series analytics, feed real-time dashboards, create real-time alerts/notifications.</li>
<li>Sits over Kinesis Data Streams and Kinesis Data Firehose.</li>
</ul>

<h4 id="kda-components">Application Components</h4>
<ul>
<li><strong>Input:</strong> Streaming source.</li>
<li><strong>Application Code:</strong> SQL statements for processing.</li>
<li><strong>Output:</strong> In-application streams for intermediate results.</li>
</ul>

<h4 id="kda-inputs">Input & Output</h4>
<ul>
<li><strong>Input Types:</strong> Streaming data sources (continuous) and Reference data sources (static data for enrichment).</li>
<li><strong>Destinations:</strong> Persist results to S3, Redshift, Elasticsearch, and Kinesis Data Streams.</li>
<li>IAM provides permissions to read from sources and write to destinations.</li>
</ul>
<hr>

<h3 id="kinesis-client-library">Kinesis Client Library (KCL)</h3>
<ul>
<li><strong>Definition:</strong> A Java library (also available for other languages) that helps read records from a Kinesis Data Stream with distributed applications.</li>
<li>Helps consumers process data in a distributed, fault-tolerant manner.</li>
<li>Abstraction Layer: Provides an abstraction specifically for processing data in a consumer role, different from the raw Kinesis Data Streams API.</li>
<li><strong>How it works:</strong>
<ul>
<li>Instantiates a worker, connects to stream, enumerates shards.</li>
<li>Coordinates shard associations with other workers.</li>
<li>Instantiates a record processor for every shard it manages.</li>
<li>Pulls records, pushes to processor, checkpoints processed records to DynamoDB. (<strong>Exam Tip!</strong>)</li>
<li>Balances shard-worker associations during scaling (split/merge).</li>
</ul>
</li>
<li><strong>Scaling Consumers:</strong>
<ul>
<li>Ensures exactly one KCL worker/record processor per shard.</li>
<li>Number of instances should generally not exceed number of shards (except for standby).</li>
<li>One worker can process multiple shards.</li>
</ul>
</li>
<li>Can run on EC2, Elastic Beanstalk, on-premises servers.</li>
<li>Records are read in order at the shard level.</li>
</ul>
<hr>

<h3 id="kinesis-security">Kinesis Security (General)</h3>
<ul>
<li><strong>Authorization:</strong> Control access using IAM policies.</li>
<li><strong>Encryption in Flight:</strong> HTTPS endpoints.</li>
<li><strong>Encryption at Rest:</strong> Server-Side Encryption (SSE) using KMS.</li>
<li>Possible to encrypt/decrypt data on the client side.</li>
<li><strong>Network:</strong> VPC endpoints available for Kinesis to access within a VPC.</li>
</ul>
<hr>

<h3 id="sqs-sns-kinesis-compare">SQS vs SNS vs Kinesis Comparison</h3>
<div class="table-responsive-wrapper">
<table class="styled-table">
<thead>
<tr>
<th>Characteristic</th>
<th>SQS</th>
<th>SNS</th>
<th>Kinesis Data Streams</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Delivery Model</strong></td>
<td>Consumers pull data.</td>
<td>Push data to many subscribers.</td>
<td>Consumers pull data.</td>
</tr>
<tr>
<td><strong>Message Persistence</strong></td>
<td>Data deleted after being consumed.</td>
<td>Data is not persisted (lost if not immediately consumed).</td>
<td>Data persists for X days (24h-7d), replayable.</td>
</tr>
<tr>
<td><strong>Consumers</strong></td>
<td>As many workers (consumers) as needed.</td>
<td>Up to 10,000,000 subscribers.</td>
<td>As many consumers as needed (KCL manages shard-to-worker mapping).</td>
</tr>
<tr>
<td><strong>Throughput Provisioning</strong></td>
<td>No need to provision.</td>
<td>No need to provision.</td>
<td>Must provision throughput (by managing shards).</td>
</tr>
<tr>
<td><strong>Ordering Guarantee</strong></td>
<td>No ordering (Standard); FIFO for strict order.</td>
<td>No ordering guarantee.</td>
<td>Ordering at the shard level.</td>
</tr>
<tr>
<td><strong>Primary Use Case</strong></td>
<td>Decoupling, individual message processing, buffering.</td>
<td>Notifications, fan-out architecture (Pub/Sub).</td>
<td>Real-time big data processing, analytics, ETL, data replay.</td>
</tr>
</tbody>
</table>
</div>
<hr>

<h3 id="kinesis-exam-tips">Important Exam Tips & Tricks</h3>
<ul>
<li><strong>Managed vs. Unmanaged:</strong>
<ul>
<li><strong>Data Streams:</strong> You manage shards (scaling).</li>
<li><strong>Firehose & Analytics:</strong> Fully managed (no shards to manage for Firehose, SQL-based for Analytics).</li>
</ul>
</li>
<li><strong>Key Differentiator (Data Streams vs. Firehose):</strong>
<ul>
<li><strong>Data Streams:</strong> For custom applications that need to process streaming data in real-time and potentially store it for a short period, allowing data replay. You write the consumer application.</li>
<li><strong>Firehose:</strong> For loading streaming data into specific AWS destinations (S3, Redshift, ES, Splunk) with minimal effort. It's fully managed and handles batching, compression, and encryption automatically. You don't write a consumer application.</li>
</ul>
</li>
<li><strong>Partition Key:</strong> Crucial for Kinesis Data Streams. It determines which shard a record goes into, ensuring ordering within a shard and even distribution of data. (<strong>Frequent Exam Question!</strong>)</li>
<li><strong>KCL & DynamoDB:</strong> Remember KCL uses DynamoDB for checkpointing (tracking processed records) and coordinating workers. (<strong>Key Exam Point!</strong>)</li>
<li><strong>KCL Scaling:</strong> Understand that the number of KCL instances should ideally match the number of shards for optimal performance, as each shard is processed by one KCL instance.</li>
<li><strong>Record Size:</strong> Remember the 1MB limit for Kinesis records.</li>
<li><strong>Retention Period:</strong> Know the default (24 hours) and max (7 days) retention for Data Streams.</li>
<li><strong>Replication:</strong> Kinesis Data Streams replicates across 3 AZs for high durability.</li>
<li><strong>Encryption:</strong> KMS is used for encryption at rest across Kinesis services.</li>
<li><strong>Use Cases:</strong> Be able to identify which Kinesis service fits a given scenario (e.g., "real-time dashboards" -> Analytics, "loading logs to S3" -> Firehose, "custom real-time processing" -> Data Streams).</li>
</ul>
<hr>